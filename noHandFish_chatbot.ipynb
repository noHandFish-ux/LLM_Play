{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b316e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0852ea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26340\\3859023737.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=llm_name, temperature=0,openai_api_key=\"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\")\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26340\\3859023737.py:3: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm.predict(\"你好\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好！有什么可以帮助你的吗？'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0,openai_api_key=\"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\")\n",
    "llm.predict(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828a8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import panel as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dad1852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "persist_directory='docs/chroma/matplotlib'\n",
    "embedding = OpenAIEmbeddings(openai_api_key=\"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\")\n",
    "vectordb=Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "\n",
    "question=\"这门课的主要内容是什么？\"\n",
    "docs=vectordb.similarity_search(question,k=3)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7789ad13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26340\\548549784.py:18: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这门课的主题是Matplotlib初相识，介绍了Matplotlib的基本概念、绘图例子以及Figure的组成。\n",
      "谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "# 构建 prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答案。最多使用三句话。尽量使答案简明扼要。总是在回答的最后说“谢谢你的提问！”。\n",
    "{context}\n",
    "问题: {question}\n",
    "有用的回答:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
    "\n",
    "# 运行 chain\n",
    "from langchain.chains import RetrievalQA\n",
    "question = \"这门课的主题是什么？\"\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectordb.as_retriever(),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
    "\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ebf09d",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebca89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4b4cf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的，这门课程会涉及到Python编程语言的使用，特别是在数据可视化方面会使用到Python。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectordb.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")\n",
    "question = \"这门课会学习python嘛？\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0708e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据提供的上下文，这门课程需要学习Python是因为Matplotlib是一个Python 2D绘图库，用于生成出版物质量的图形，绘制各种静态、动态、交互式的图表。Matplotlib可以在Python脚本、Python和IPython Shell、Jupyter notebook、Web应用程序服务器以及各种图形用户界面工具包中使用。因此，学习Python可以帮助理解Matplotlib库的使用，从而进行数据可视化和图形绘制。\n"
     ]
    }
   ],
   "source": [
    "question = \"为什么这门课需要这个前提？\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f5b3f3",
   "metadata": {},
   "source": [
    "# 适用于文档的聊天机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b88eea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "# from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3a1b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(file, chain_type, k):\n",
    "    # 载入\n",
    "    loader = PyPDFLoader(file)\n",
    "    document = loader.load()\n",
    "    # 切割\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=800)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    # embeddings\n",
    "    embedding = OpenAIEmbeddings(openai_api_key=\"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\")\n",
    "    # 创建数据库\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embedding)\n",
    "    # 检索器\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    # 创建chatbot链：\n",
    "    qa =ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        chain_type=chain_type,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True\n",
    "    )\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "450b0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d56cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(file, chain_type, k):\n",
    "    \"\"\"\n",
    "    该函数用于加载 PDF 文件，切分文档，生成文档的嵌入向量，创建向量数据库，定义检索器，并创建聊天机器人实例。\n",
    "\n",
    "    参数:\n",
    "    file (str): 要加载的 PDF 文件路径。\n",
    "    chain_type (str): 链类型，用于指定聊天机器人的类型。\n",
    "    k (int): 在检索过程中，返回最相似的 k 个结果。\n",
    "\n",
    "    返回:\n",
    "    qa (ConversationalRetrievalChain): 创建的聊天机器人实例。\n",
    "    \"\"\"\n",
    "    # 载入文档\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    # 切分文档\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    # 定义 Embeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # 根据数据创建向量数据库\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    # 定义检索器\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    # 创建 chatbot 链，Memory 由外部管理\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0), \n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "    )\n",
    "    return qa \n",
    "\n",
    "import panel as pn\n",
    "import param\n",
    "\n",
    "# 用于存储聊天记录、回答、数据库查询和回复\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query  = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "    \n",
    "    def __init__(self,  **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.panels = []\n",
    "        self.loaded_file = \"docs/matplotlib/第一回：Matplotlib初相识.pdf\"\n",
    "        self.qa = load_db(self.loaded_file,\"stuff\", 4)\n",
    "    \n",
    "    # 将文档加载到聊天机器人中\n",
    "    def call_load_db(self, count):\n",
    "        \"\"\"\n",
    "        count: 数量\n",
    "        \"\"\"\n",
    "        if count == 0 or file_input.value is None:  # 初始化或未指定文件 :\n",
    "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            file_input.save(\"temp.pdf\")  # 本地副本\n",
    "            self.loaded_file = file_input.filename\n",
    "            button_load.button_style=\"outline\"\n",
    "            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
    "            button_load.button_style=\"solid\"\n",
    "        self.clr_history()\n",
    "        return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "\n",
    "    # 处理对话链\n",
    "    def convchain(self, query):\n",
    "        \"\"\"\n",
    "        query: 用户的查询\n",
    "        \"\"\"\n",
    "        if not query:\n",
    "            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown(\"\", width=600)), scroll=True)\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.extend([(query, result[\"answer\"])])\n",
    "        self.db_query = result[\"generated_question\"]\n",
    "        self.db_response = result[\"source_documents\"]\n",
    "        self.answer = result['answer'] \n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=600)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=600, style={'background-color': '#F6F6F6'}))\n",
    "        ])\n",
    "        inp.value = ''  # 清除时清除装载指示器\n",
    "        return pn.WidgetBox(*self.panels,scroll=True)\n",
    "    \n",
    "    # 获取最后发送到数据库的问题\n",
    "    @param.depends('db_query ', )\n",
    "    def get_lquest(self):\n",
    "        if not self.db_query :\n",
    "            return pn.Column(\n",
    "                pn.Row(pn.pane.Markdown(f\"Last question to DB:\", styles={'background-color': '#F6F6F6'})),\n",
    "                pn.Row(pn.pane.Str(\"no DB accesses so far\"))\n",
    "            )\n",
    "        return pn.Column(\n",
    "            pn.Row(pn.pane.Markdown(f\"DB query:\", styles={'background-color': '#F6F6F6'})),\n",
    "            pn.pane.Str(self.db_query )\n",
    "        )\n",
    "    \n",
    "    # 获取数据库返回的源文件\n",
    "    @param.depends('db_response', )\n",
    "    def get_sources(self):\n",
    "        if not self.db_response:\n",
    "            return \n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Result of DB lookup:\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for doc in self.db_response:\n",
    "            rlist.append(pn.Row(pn.pane.Str(doc)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    # 获取当前聊天记录\n",
    "    @param.depends('convchain', 'clr_history') \n",
    "    def get_chats(self):\n",
    "        if not self.chat_history:\n",
    "            return pn.WidgetBox(pn.Row(pn.pane.Str(\"No History Yet\")), width=600, scroll=True)\n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Current Chat History variable\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for exchange in self.chat_history:\n",
    "            rlist.append(pn.Row(pn.pane.Str(exchange)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "    \n",
    "    # 清除聊天记录\n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4e8db40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 初始化聊天机器人\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cb = \u001b[43mcbfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 定义界面的小部件\u001b[39;00m\n\u001b[32m      5\u001b[39m file_input = pn.widgets.FileInput(accept=\u001b[33m'\u001b[39m\u001b[33m.pdf\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;66;03m# PDF 文件的文件输入小部件\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mcbfs.__init__\u001b[39m\u001b[34m(self, **params)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28mself\u001b[39m.panels = []\n\u001b[32m     48\u001b[39m \u001b[38;5;28mself\u001b[39m.loaded_file = \u001b[33m\"\u001b[39m\u001b[33mdocs/matplotlib/第一回：Matplotlib初相识.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28mself\u001b[39m.qa = \u001b[43mload_db\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_file\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstuff\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mload_db\u001b[39m\u001b[34m(file, chain_type, k)\u001b[39m\n\u001b[32m     18\u001b[39m docs = text_splitter.split_documents(documents)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# 定义 Embeddings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m embeddings = \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 根据数据创建向量数据库\u001b[39;00m\n\u001b[32m     22\u001b[39m db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\ProgramData\\envs\\LLM\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:214\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    213\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\ProgramData\\envs\\LLM\\Lib\\site-packages\\pydantic\\main.py:214\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    213\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    216\u001b[39m     warnings.warn(\n\u001b[32m    217\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    220\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    221\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
     ]
    }
   ],
   "source": [
    "# 初始化聊天机器人\n",
    "cb = cbfs() \n",
    "\n",
    "# 定义界面的小部件\n",
    "file_input = pn.widgets.FileInput(accept='.pdf') # PDF 文件的文件输入小部件\n",
    "button_load = pn.widgets.Button(name=\"Load DB\", button_type='primary') # 加载数据库的按钮\n",
    "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type='warning') # 清除聊天记录的按钮\n",
    "button_clearhistory.on_click(cb.clr_history) # 将清除历史记录功能绑定到按钮上\n",
    "inp = pn.widgets.TextInput( placeholder='Enter text here…') # 用于用户查询的文本输入小部件\n",
    "\n",
    "# 将加载数据库和对话的函数绑定到相应的部件上\n",
    "bound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "\n",
    "jpg_pane = pn.pane.Image( './img/convchain.jpg')\n",
    "\n",
    "# 使用 Panel 定义界面布局\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True, height=300),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab2= pn.Column(\n",
    "    pn.panel(cb.get_lquest),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(cb.get_sources ),\n",
    ")\n",
    "tab3= pn.Column(\n",
    "    pn.panel(cb.get_chats),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab4=pn.Column(\n",
    "    pn.Row( file_input, button_load, bound_button_load),\n",
    "    pn.Row( button_clearhistory, pn.pane.Markdown(\"Clears chat history. Can use to start a new topic\" )),\n",
    "    pn.layout.Divider(),\n",
    "    pn.Row(jpg_pane.clone(width=400))\n",
    ")\n",
    "# 将所有选项卡合并为一个仪表盘\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# ChatWithYourData_Bot')),\n",
    "    pn.Tabs(('Conversation', tab1), ('Database', tab2), ('Chat History', tab3),('Configure', tab4))\n",
    ")\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0377a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
