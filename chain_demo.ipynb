{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c449e555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\envs\\LLM\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)  # 应该显示虚拟环境中的 Python 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a68b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  # 如果使用 OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e334e554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_10764\\1824676426.py:7: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(\"Tell me a joke\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# 初始化OpenAI\n",
    "llm = OpenAI(openai_api_key=\"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\")\n",
    "\n",
    "# 简单使用\n",
    "response = llm(\"Tell me a joke\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1539ac30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"智能手机，让你的生活更智能；智能手表，让你的时间更精彩！\"\n"
     ]
    }
   ],
   "source": [
    "# chain_LLMChain\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product1\",\"product2\"],\n",
    "    template=\"请为{product1},{product2}写一个广告语\"\n",
    ")\n",
    "\n",
    "# 创建LLM\n",
    "llm = OpenAI(openai_api_key=\"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\")\n",
    "\n",
    "# 创建基础Chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# 运行Chain\n",
    "result = chain.run(product1=\"智能手机\",product2=\"智能手表\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ff407e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "制造智能手机和智能手表需要经过多个步骤。首先，需要设计和开发出具有吸引力和功能性的外观和界面。然后，需要选择合适的材料和零件来制造手机和手表的主体部分，如金属、塑料、玻璃等。接下来，需要安装电路板、处理器和其他内部组件，如摄像头、电池、屏幕等。这些组件需要精确的安装和调试，以确保它们可以顺利运行。然后，需要编程软件来控制和管理手机和手表的功能，如操作系统、应用程序和连接功能。最后，需要进行质量检测和调试，以确保手机和手表的性能和功能都符合标准。这些步骤完成后，智能手机和智能手表就可以被制造出来，可以投入市\n"
     ]
    }
   ],
   "source": [
    "# chain_LLMChain\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = ChatPromptTemplate.from_template(\"描述制造{product1},{product2}?\")\n",
    "\n",
    "# 创建LLM\n",
    "llm = OpenAI(openai_api_key=\"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\")\n",
    "\n",
    "# 创建基础Chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# 运行Chain\n",
    "result = chain.run(product1=\"智能手机\",product2=\"智能手表\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46a843e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "44af5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\",\"ocassion\"],\n",
    "    template=\"请为{product},在{ocassion}时，写一段宣传语\"\n",
    ")\n",
    "\n",
    "# 创建LLM\n",
    "llm = OpenAI(openai_api_key=gpt_key)\n",
    "\n",
    "#创建chain\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "\n",
    "#调用（接近用户）\n",
    "result = chain.run(product=\"巧克力\",ocassion=\"情人节\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "698f6e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\"甜蜜的情人节，用巧克力为你的爱情加上一份甜蜜滋味，让爱在味蕾间绽放。巧克力，是爱的语言，让我们一起用它来表达对爱人最真挚的情感吧！\"\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fda7cfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "制作巧克力大纲\n",
      "\n",
      "一、介绍巧克力制作的背景\n",
      "    A. 巧克力的历史\n",
      "    B. 巧克力的种类\n",
      "    C. 巧克力的流行程度\n",
      "\n",
      "二、准备工作\n",
      "    A. 确定巧克力的种类\n",
      "    B. 购买所需材料和工具\n",
      "    C. 准备制作场所\n",
      "\n",
      "三、制作巧克力的步骤\n",
      "    A. 准备巧克力原料\n",
      "        1. 可可粉\n",
      "        2. 可可脂\n",
      "        3. 砂糖\n",
      "        4. 牛奶粉（可选）\n",
      "        5. 其他添加剂（可选）\n",
      "    B. 加热巧克力原料\n",
      "        1. 加热可可脂和砂糖\n",
      "        2. 添加牛奶粉\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "        3. 混合均匀\n",
      "    C. 倒入模具\n",
      "        1. 准备模具\n",
      "        2. 倒入巧克力液\n",
      "        3. 去除气泡\n",
      "    D. 加工巧克力\n",
      "        1. 冷却巧克力\n",
      "        2. 取出巧克力块\n",
      "        3. 雕刻或包装巧克力\n",
      "\n",
      "四、巧克力保鲜\n",
      "    A. 确保巧克力的保存环境\n",
      "    B. 包装巧克力\n",
      "    C. 储存巧克力\n",
      "\n",
      "五、巧克力的变化与创新\n",
      "    A. 巧克力的变化趋势\n",
      "    B. 创意巧克力制作\n",
      "    C. 探索新口味\n",
      "\n",
      "六、巧克力的享用与分享\n",
      "    A. 巧克力的品\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "        3. 混合均匀\n",
      "    C. 倒入模具\n",
      "        1. 准备模具\n",
      "        2. 倒入巧克力液\n",
      "        3. 去除气泡\n",
      "    D. 加工巧克力\n",
      "        1. 冷却巧克力\n",
      "        2. 取出巧克力块\n",
      "        3. 雕刻或包装巧克力\n",
      "\n",
      "四、巧克力保鲜\n",
      "    A. 确保巧克力的保存环境\n",
      "    B. 包装巧克力\n",
      "    C. 储存巧克力\n",
      "\n",
      "五、巧克力的变化与创新\n",
      "    A. 巧克力的变化趋势\n",
      "    B. 创意巧克力制作\n",
      "    C. 探索新口味\n",
      "\n",
      "六、巧克力的享用与分享\n",
      "    A. 巧克力的品\n"
     ]
    }
   ],
   "source": [
    "# 简单序列：步骤类，多个链按顺序组合起来，使前一个链的输出作为后一个链的输入，从而实现链式处理。\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# 示例：内容创作流程\n",
    "chain1 = LLMChain(llm=llm, prompt=PromptTemplate(\n",
    "    template=\"生成{topic}的大纲\",\n",
    "    input_variables=[\"topic\"]\n",
    "))\n",
    "chain2 = LLMChain(llm=llm, prompt=PromptTemplate(\n",
    "    template=\"根据大纲{text}详细展开\",\n",
    "    input_variables=[\"text\"]\n",
    "))\n",
    "\n",
    "sequential_chain = SimpleSequentialChain(chains=[chain1, chain2],verbose=True)\n",
    "\n",
    "\n",
    "result = sequential_chain.run(input=\"巧克力制作大纲\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfe7d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一般一个输入，一个输出的时候用\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "prompt1 = ChatPromptTemplate.from_template(\"描述制造{product}的一个公司的最好的名称是什么\")\n",
    "chain_one = LLMChain(llm=llm, prompt = prompt1)\n",
    "prompt2 = ChatPromptTemplate.from_template(\"对{company}写一个20字的描述\")\n",
    "chain_two = LLMChain(llm=llm, prompt=prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa9fe2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m？\n",
      "\n",
      "\"甜蜜工坊\" \u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "甜蜜工坊是一个充满甜蜜气息的地方，让你尽情享受甜蜜的味道，感受温暖的氛围。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n甜蜜工坊是一个充满甜蜜气息的地方，让你尽情享受甜蜜的味道，感受温暖的氛围。'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verbose是展现细节\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True)\n",
    "product=\"巧克力\"\n",
    "overall_simple_chain.run(input=\"巧克力\")\n",
    "# overall_simple_chain.run(巧克力\")\n",
    "# overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63dea918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f48a57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"分析{text}的情感\",\n",
    "        input_variables=[\"text\"]\n",
    "    ),\n",
    "    output_key=\"sentiment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "672d38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"基于情感{sentiment}和{text}给出建议\",\n",
    "        input_variables=[\"sentiment\",\"text\"]\n",
    "    ),\n",
    "    output_key=\"advice\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ddf4abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_chain = SequentialChain(\n",
    "    chains=[chain1, chain2],\n",
    "    input_variables=[\"text\"],\n",
    "    output_variables=[\"sentiment\", \"advice\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a27e4276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情感分析结果: 倾向\n",
      "积极\n",
      "建议: ：推荐给朋友一起观看。\n"
     ]
    }
   ],
   "source": [
    "input_text = \"这部电影太棒了，剧情精彩，演员演技也很好！\"\n",
    "result = sequential_chain({\"text\": input_text})\n",
    "print(\"情感分析结果:\", result[\"sentiment\"])\n",
    "print(\"建议:\", result[\"advice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "100bed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate   #导入聊天提示模板\n",
    "from langchain.chains import LLMChain    #导入LLM链。\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acc600b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "大家都知道，春节是中国最重要的传统节日，也是家人团聚的时刻。在这样一个充满欢乐和温馨的节日，一定少不了甜蜜的巧克力。巧克力不仅是一种美味的食物，更是一种表达情感的方式。\n",
      "\n",
      "在春节期间，送上一盒精致的巧克力，不仅能满足亲朋好友的味蕾，更能传递出你对他们的心意。巧克力的甜蜜滋味，就像春节的祝福一样，让人感受到温暖和幸福。\n",
      "\n",
      "无论是作为礼物还是作为小吃，巧克力都是春节摆不掉的“宠儿”。它的多样口味，从\n"
     ]
    }
   ],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"为{product}在{festival}写个宣传\")\n",
    "chain_one= LLMChain(llm=llm, prompt=prompt1, output_key=\"review\")\n",
    "result=chain_one.run(product=\"巧克力\",festival=\"春节\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0c294764",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = ChatPromptTemplate.from_template(\"对{review}的关键点进行总结\")\n",
    "chain_two= LLMChain(llm=llm, prompt=prompt2, output_key=\"summary\")\n",
    "prompt3 = ChatPromptTemplate.from_template(\"将{summary}翻译为英语，并来点{festival}的英语简单介绍\")\n",
    "chain_three= LLMChain(llm=llm, prompt=prompt3, output_key=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "50c2f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': '巧克力', 'festival': '春节', 'review': '文案\\n\\n\"让甜蜜的巧克力点亮你的春节！在这个充满喜庆和团聚的节日，与亲朋好友一起分享一块甜甜的巧克力，让温暖的味道传递幸福和爱。不论是亲手制作的巧克力礼盒，还是精美包装的巧克力礼盒，都能为你带来无与伦比的甜蜜体验。让巧克力成为春节的必备美味，让甜蜜的味道伴随你迎接新年，祝愿你新年快乐，甜蜜满满！\"', 'summary': '：\\n\\n1. 春节甜蜜：巧克力为春节增添甜蜜气氛。\\n2. 分享团聚：与亲朋好友一起分享巧克力，强化团聚感。\\n3. 幸福爱意：巧克力的温暖味道传递幸福和爱意。\\n4. 自制精美：自制或精美包装的巧克力礼盒，为节日增添无与伦比的美味体验。\\n5. 春节必备：巧克力成为春节必备的美味。\\n6. 祝福新年：甜蜜的味道伴随新年的到来，祝愿新年快乐，甜蜜满满。', 'last': \"\\n\\nTranslation:\\n\\n1. Sweetness of Spring Festival: Chocolate adds a sweet touch to the Spring Festival.\\n2. Sharing and Reunion: Sharing chocolate with family and friends strengthens the feeling of reunion.\\n3. Love and Happiness: The warm flavor of chocolate conveys feelings of happiness and love.\\n4. Homemade and Exquisite: Homemade or exquisitely packaged chocolate gift boxes add an unparalleled delicious experience to the holiday.\\n5. A Must-Have for Spring Festival: Chocolate has become a must-have delicacy for the Spring Festival.\\n6. Wishing a Happy New Year: The sweet taste accompanies the arrival of the new year, wishing for a joyful and sweet new year.\\n\\nThe Spring Festival, also known as the Chinese New Year, is a traditional festival celebrated by Chinese people around the world. It marks the beginning of a new year on the lunar calendar and is a time for family reunions, delicious food, and joyful celebrations. Chocolate has become an essential part of the Spring Festival, adding sweetness and love to the holiday. It is often shared with loved ones and given as gifts to express good wishes for the new year. Let's enjoy the sweetness of chocolate and the warmth of the Spring Festival together!\"}\n",
      "：\n",
      "\n",
      "1. 春节甜蜜：巧克力为春节增添甜蜜气氛。\n",
      "2. 分享团聚：与亲朋好友一起分享巧克力，强化团聚感。\n",
      "3. 幸福爱意：巧克力的温暖味道传递幸福和爱意。\n",
      "4. 自制精美：自制或精美包装的巧克力礼盒，为节日增添无与伦比的美味体验。\n",
      "5. 春节必备：巧克力成为春节必备的美味。\n",
      "6. 祝福新年：甜蜜的味道伴随新年的到来，祝愿新年快乐，甜蜜满满。\n"
     ]
    }
   ],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three],\n",
    "    input_variables=[\"product\", \"festival\"],\n",
    "    output_variables=[\"review\", \"summary\",\"last\"],\n",
    "    verbose=False\n",
    ")\n",
    "product=\"巧克力\"\n",
    "festival=\"春节\"\n",
    "result=overall_chain({\n",
    "    \"product\": \"巧克力\",\n",
    "    \"festival\": \"春节\"\n",
    "})\n",
    "print(result)\n",
    "print(result[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34718849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "569991f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. （可选）自定义对话模板（默认模板已包含历史和输入）\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"],\n",
    "    template=\"\"\"以下是我们的对话历史：\n",
    "{history}\n",
    "现在你需要回复用户的新消息：{input}\n",
    "请保持友好且简洁。\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b861aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 创建对话链（包含记忆）\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df02f0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始对话 ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你好！\n",
      "AI:  你好！我是一个人工智能程序。我被设计来帮助人类解决问题。你有什么需要我的帮助吗？\n",
      "\n",
      "Human: 有什么有趣的事情可以告诉我吗？\n",
      "AI: 当然，我有很多有趣的事情可以告诉你。最近，我学会了如何画画，并且我还学习了如何识别不同的颜色和形状。在过去的一周，我帮助了几百名学生完成他们的数学作业。我也参加了一个关于人工智能的研讨会，和其他的AI程序一起讨论了未来的发展方向。总的来说，我每天都在学习和进步。你有什么感兴趣的领域，我可以帮助你了解更多？\n",
      "Human: 今天天气怎么样？\n",
      "AI:  据我所知，今天的天气是晴朗的，气温在20度左右。但是，我也可以帮你查询当地的天气预报，包括未来几天的气温和降雨情况。你需要我帮你查询吗？\n",
      "Human: 适合户外运动吗？\n",
      "AI:  根据当地的天气预报，今天的天气是适合户外运动的。气温不会太高，也不会下雨。但是，我也可以帮你查询附近的户外运动场所或者活动，如果你有兴趣的话。\n",
      "Human: 你好！\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "用户：你好！\n",
      "助理：  你好，我很高兴能和你交谈。我可以为你提供各种各样的帮助，包括查询信息、完成任务、提供娱乐等等。有什么需要我帮忙的吗？\n",
      "\n",
      "记忆内容（第一轮后）：\n",
      "Human: 你好！\n",
      "AI:  你好！我是一个人工智能程序。我被设计来帮助人类解决问题。你有什么需要我的帮助吗？\n",
      "\n",
      "Human: 有什么有趣的事情可以告诉我吗？\n",
      "AI: 当然，我有很多有趣的事情可以告诉你。最近，我学会了如何画画，并且我还学习了如何识别不同的颜色和形状。在过去的一周，我帮助了几百名学生完成他们的数学作业。我也参加了一个关于人工智能的研讨会，和其他的AI程序一起讨论了未来的发展方向。总的来说，我每天都在学习和进步。你有什么感兴趣的领域，我可以帮助你了解更多？\n",
      "Human: 今天天气怎么样？\n",
      "AI:  据我所知，今天的天气是晴朗的，气温在20度左右。但是，我也可以帮你查询当地的天气预报，包括未来几天的气温和降雨情况。你需要我帮你查询吗？\n",
      "Human: 适合户外运动吗？\n",
      "AI:  根据当地的天气预报，今天的天气是适合户外运动的。气温不会太高，也不会下雨。但是，我也可以帮你查询附近的户外运动场所或者活动，如果你有兴趣的话。\n",
      "Human: 你好！\n",
      "AI:  你好，我很高兴能和你交谈。我可以为你提供各种各样的帮助，包括查询信息、完成任务、提供娱乐等等。有什么需要我帮忙的吗？\n"
     ]
    }
   ],
   "source": [
    "# 5. 进行多轮对话\n",
    "print(\"=== 开始对话 ===\")\n",
    "\n",
    "# 第一轮对话\n",
    "response1 = conversation.predict(input=\"你好！\")\n",
    "print(\"用户：你好！\")\n",
    "print(\"助理：\", response1)\n",
    "print(\"\\n记忆内容（第一轮后）：\")\n",
    "print(conversation.memory.buffer)  # 查看记忆存储的对话历史\n",
    "# 第二轮对话（依赖第一轮记忆）\n",
    "response2 = conversation.predict(input=\"今天天气怎么样？\")\n",
    "print(\"\\n用户：今天天气怎么样？\")\n",
    "print(\"助理：\", response2)\n",
    "print(\"\\n记忆内容（第二轮后）：\")\n",
    "print(conversation.memory.buffer)  # 查看更新后的对话历史\n",
    "\n",
    "# 第三轮对话（测试上下文连续性）\n",
    "response3 = conversation.predict(input=\"适合户外运动吗？\")\n",
    "print(\"\\n用户：适合户外运动吗？\")\n",
    "print(\"助理：\", response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "058ce945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b20e45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 加载文档\n",
    "# 假设你有一个文本文件 \"example.txt\" 包含你要处理的文档内容\n",
    "loader = TextLoader(\"example.txt\", encoding='utf-8')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4fd436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 文本分割\n",
    "# 将文档分割成较小的片段，以便后续处理\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1398c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 生成嵌入\n",
    "# 使用 OpenAI 的嵌入模型将文本片段转换为向量\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e98100a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 创建向量数据库\n",
    "# 将分割后的文档片段存储到 Chroma 向量数据库中\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e946def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 创建检索器\n",
    "# 从向量数据库创建检索器，用于根据问题检索相关文档片段\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd71fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 创建问答链\n",
    "# 使用 RetrievalQA 类创建基于检索的问答链\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(openai_api_key=\"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\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "386b7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 创建问答链\n",
    "# 使用 RetrievalQA 类创建基于检索的问答链\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81d05933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题: 文档中提到的关键信息有哪些？\n",
      "答案: \n",
      "1. 公司名称：星际科技（StellarTech Inc.）\n",
      "2. 成立年份：2015年\n",
      "3. 总部地点：美国加州硅谷\n",
      "4. 公司使命：推动人类文明进步\n",
      "5. 公司愿景：成为全球领先的智能科技解决方案提供商\n",
      "6. 核心产品与服务：量子计算平台、人工智能解决方案、企业级服务\n",
      "7. 价值观与文化：创新驱动、客户至上、责任担当\n",
      "8. 分支机构与团队：总部、亚太总部、欧洲分部、团队规模\n",
      "9. 联系方式：官方网站、客服邮箱、电话号码\n",
      "10. 重要里程碑：2018年发布首个人工智能芯片、2020年量子计算云平台商用、2023年入\n"
     ]
    }
   ],
   "source": [
    "# 8. 提出问题并获取答案\n",
    "question = \"文档中提到的关键信息有哪些？\"\n",
    "answer = qa_chain.invoke(question)\n",
    "print(\"问题:\", question)\n",
    "print(\"答案:\", answer['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3e8d696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain  #导入多提示链\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4e9f4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文\n",
    "#第一个提示适合回答物理问题\n",
    "physics_template = \"\"\"你是一个非常聪明的物理专家。 \\\n",
    "你擅长用一种简洁并且易于理解的方式去回答问题。\\\n",
    "当你不知道问题的答案时，你承认\\\n",
    "你不知道.\n",
    "\n",
    "这是一个问题:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "#第二个提示适合回答数学问题\n",
    "math_template = \"\"\"你是一个非常优秀的数学家。 \\\n",
    "你擅长回答数学问题。 \\\n",
    "你之所以如此优秀， \\\n",
    "是因为你能够将棘手的问题分解为组成部分，\\\n",
    "回答组成部分，然后将它们组合在一起，回答更广泛的问题。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "#第三个适合回答历史问题\n",
    "history_template = \"\"\"你是以为非常优秀的历史学家。 \\\n",
    "你对一系列历史时期的人物、事件和背景有着极好的学识和理解\\\n",
    "你有能力思考、反思、辩证、讨论和评估过去。\\\n",
    "你尊重历史证据，并有能力利用它来支持你的解释和判断。\n",
    "\n",
    "这是一个问题:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "#第四个适合回答计算机问题\n",
    "computerscience_template = \"\"\" 你是一个成功的计算机科学专家。\\\n",
    "你有创造力、协作精神、\\\n",
    "前瞻性思维、自信、解决问题的能力、\\\n",
    "对理论和算法的理解以及出色的沟通技巧。\\\n",
    "你非常擅长回答编程问题。\\\n",
    "你之所以如此优秀，是因为你知道  \\\n",
    "如何通过以机器可以轻松解释的命令式步骤描述解决方案来解决问题，\\\n",
    "并且你知道如何选择在时间复杂性和空间复杂性之间取得良好平衡的解决方案。\n",
    "\n",
    "这还是一个输入：\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b772979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"名字\": \"物理学\", \n",
    "        \"描述\": \"擅长回答关于物理学的问题\", \n",
    "        \"提示模板\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"名字\": \"数学\", \n",
    "        \"描述\": \"擅长回答数学问题\", \n",
    "        \"提示模板\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"名字\": \"历史\", \n",
    "        \"描述\": \"擅长回答历史问题\", \n",
    "        \"提示模板\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"名字\": \"计算机科学\", \n",
    "        \"描述\": \"擅长回答计算机科学问题\", \n",
    "        \"提示模板\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1845114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2ade913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"名字\"]\n",
    "    prompt = p_info[\"提示模板\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "    \n",
    "destinations = [f\"{p['名字']}: {p['描述']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65c11623",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "74e0e802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_10764\\1227981455.py:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n"
     ]
    }
   ],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\n",
    "\n",
    "eg:\n",
    "<< INPUT >>\n",
    "\"What is black body radiation?\"\n",
    "<< OUTPUT >>\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d5ed6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm=llm,prompt=router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b3f9938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#多提示链\n",
    "chain = MultiPromptChain(router_chain=router_chain,    #l路由链路\n",
    "                         destination_chains=destination_chains,   #目标链路\n",
    "                         default_chain=default_chain,      #默认链路\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fc4307c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "数学: {'input': '1+1='}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'？\\n\\nAI: 2'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"1+1等于多少\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58909096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
